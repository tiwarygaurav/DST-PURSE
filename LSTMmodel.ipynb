{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde65147-8280-498e-b97f-6eb28f0f8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('updateddata.csv')\n",
    "\n",
    "\n",
    "# Assuming NO2 and SO2 are columns in the dataset, we'll select them\n",
    "no2_data = data['NO2'].values\n",
    "so2_data = data['SO2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53062523-490b-4cce-bf6d-70b1542d8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data for LSTM\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "no2_data_scaled = scaler.fit_transform(no2_data.reshape(-1, 1))\n",
    "so2_data_scaled = scaler.fit_transform(so2_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9e206f-34e0-44f2-a667-b27b2a0f2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 59  # Using 59 months to predict the 60th month\n",
    "\n",
    "# NO2 Data\n",
    "X_no2, y_no2 = create_dataset(no2_data_scaled, time_step)\n",
    "X_no2 = X_no2.reshape(X_no2.shape[0], X_no2.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ad811a-1148-437e-a52f-b57e2b399e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model_no2 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb838b0-1b7b-42f6-8ee3-47aeb6366267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 27ms/step - loss: 0.0072\n",
      "Epoch 2/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 27ms/step - loss: 0.0068\n",
      "Epoch 3/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - loss: 0.0061\n",
      "Epoch 4/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - loss: 0.0060\n",
      "Epoch 5/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - loss: 0.0059\n",
      "Epoch 6/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - loss: 0.0056\n",
      "Epoch 7/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0062\n",
      "Epoch 8/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 9/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0074\n",
      "Epoch 10/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0060\n",
      "Epoch 11/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0055\n",
      "Epoch 12/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0057\n",
      "Epoch 13/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0068\n",
      "Epoch 14/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0063\n",
      "Epoch 15/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0060\n",
      "Epoch 16/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0058\n",
      "Epoch 17/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0050\n",
      "Epoch 18/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0055\n",
      "Epoch 19/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0062\n",
      "Epoch 20/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0057\n",
      "Epoch 22/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0053\n",
      "Epoch 23/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0052\n",
      "Epoch 24/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0064\n",
      "Epoch 25/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0054\n",
      "Epoch 26/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0062\n",
      "Epoch 27/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0068\n",
      "Epoch 28/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0052\n",
      "Epoch 29/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0059\n",
      "Epoch 30/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0057\n",
      "Epoch 31/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 32/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 33/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0058\n",
      "Epoch 34/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0050\n",
      "Epoch 35/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0053\n",
      "Epoch 36/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0056\n",
      "Epoch 37/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - loss: 0.0056\n",
      "Epoch 38/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - loss: 0.0054\n",
      "Epoch 39/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0051\n",
      "Epoch 40/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0063\n",
      "Epoch 41/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0055\n",
      "Epoch 42/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0052\n",
      "Epoch 43/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0061\n",
      "Epoch 44/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0050\n",
      "Epoch 45/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0044\n",
      "Epoch 46/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0057\n",
      "Epoch 47/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0044\n",
      "Epoch 48/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0054\n",
      "Epoch 49/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0064\n",
      "Epoch 50/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19397a458d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train NO2 model\n",
    "model_no2.fit(X_no2, y_no2, epochs=50, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326e3d7d-cb3f-4f04-a39e-cb6717f99821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict NO2\n",
    "no2_pred = model_no2.predict(X_no2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715b5378-4782-4685-af10-82c53ef10cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions\n",
    "no2_pred = scaler.inverse_transform(no2_pred)\n",
    "y_no2 = scaler.inverse_transform(y_no2.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3391747-aef1-4bc4-ba76-ae2d8ec8ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO2 RMSE: 0.0003277267447792922\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_no2 = np.sqrt(mean_squared_error(y_no2, no2_pred))\n",
    "\n",
    "print(f'NO2 RMSE: {rmse_no2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a179ce-6611-4145-9285-49f0c31dc351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0068\n",
      "Epoch 2/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 3/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 4/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0084\n",
      "Epoch 5/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0064\n",
      "Epoch 6/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0068\n",
      "Epoch 7/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 8/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 9/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0077\n",
      "Epoch 10/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 11/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 12/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0066\n",
      "Epoch 13/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0075\n",
      "Epoch 14/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0065\n",
      "Epoch 16/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0066\n",
      "Epoch 17/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 18/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0052\n",
      "Epoch 19/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0064\n",
      "Epoch 20/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 21/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 22/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0060\n",
      "Epoch 23/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0054\n",
      "Epoch 24/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0058\n",
      "Epoch 25/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0063\n",
      "Epoch 26/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0061\n",
      "Epoch 27/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0053\n",
      "Epoch 28/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0056\n",
      "Epoch 29/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0061\n",
      "Epoch 30/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 31/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0057\n",
      "Epoch 32/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0054\n",
      "Epoch 33/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0048\n",
      "Epoch 34/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0062\n",
      "Epoch 35/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0057\n",
      "Epoch 36/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0060\n",
      "Epoch 37/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 38/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0051\n",
      "Epoch 39/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0053\n",
      "Epoch 40/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0049\n",
      "Epoch 41/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 42/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0061\n",
      "Epoch 43/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0055\n",
      "Epoch 44/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0060\n",
      "Epoch 45/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 46/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 47/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 48/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0050\n",
      "Epoch 49/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 50/50\n",
      "\u001b[1m1766/1766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0088\n",
      "Epoch 2/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0082\n",
      "Epoch 3/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0073\n",
      "Epoch 4/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0066\n",
      "Epoch 5/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0065\n",
      "Epoch 7/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0061\n",
      "Epoch 8/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0070\n",
      "Epoch 9/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 10/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0060\n",
      "Epoch 11/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 12/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 13/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0073\n",
      "Epoch 14/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 15/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 16/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 17/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0054\n",
      "Epoch 18/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0061\n",
      "Epoch 19/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0064\n",
      "Epoch 20/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 21/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 22/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 23/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 24/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0054\n",
      "Epoch 25/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 26/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 27/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 28/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 29/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0050\n",
      "Epoch 30/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0054\n",
      "Epoch 31/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 32/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 33/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 34/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0061\n",
      "Epoch 35/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 36/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 37/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0050\n",
      "Epoch 38/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0055\n",
      "Epoch 39/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0054\n",
      "Epoch 40/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0050\n",
      "Epoch 41/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 42/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0057\n",
      "Epoch 43/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0051\n",
      "Epoch 44/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0060\n",
      "Epoch 45/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 46/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0066\n",
      "Epoch 47/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 48/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0062\n",
      "Epoch 49/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 50/50\n",
      "\u001b[1m1767/1767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0058\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0074\n",
      "Epoch 2/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0069\n",
      "Epoch 3/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 4/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 5/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 6/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0063\n",
      "Epoch 7/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0069\n",
      "Epoch 8/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 9/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0064\n",
      "Epoch 10/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0060\n",
      "Epoch 11/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 12/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0062\n",
      "Epoch 13/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 14/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 15/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 16/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0071\n",
      "Epoch 17/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 18/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 19/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0062\n",
      "Epoch 20/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0063\n",
      "Epoch 21/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 22/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 23/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 24/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 25/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 26/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 27/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0048\n",
      "Epoch 28/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 29/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0047\n",
      "Epoch 30/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0063\n",
      "Epoch 31/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 32/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0063\n",
      "Epoch 33/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0068\n",
      "Epoch 34/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 35/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0068\n",
      "Epoch 36/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 37/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 38/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 39/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 40/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0047\n",
      "Epoch 41/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 42/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0061\n",
      "Epoch 43/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 44/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 45/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0054\n",
      "Epoch 46/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0050\n",
      "Epoch 47/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 48/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0047\n",
      "Epoch 49/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 50/50\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0050\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0074\n",
      "Epoch 2/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0073\n",
      "Epoch 3/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 4/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 5/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 6/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 7/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0061\n",
      "Epoch 8/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0068\n",
      "Epoch 9/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 10/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 11/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0061\n",
      "Epoch 12/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054\n",
      "Epoch 13/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0076\n",
      "Epoch 14/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0065\n",
      "Epoch 15/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0063\n",
      "Epoch 16/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 17/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 18/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0060\n",
      "Epoch 19/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0064\n",
      "Epoch 20/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0061\n",
      "Epoch 21/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 22/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 23/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 24/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054\n",
      "Epoch 25/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0065\n",
      "Epoch 26/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0049\n",
      "Epoch 27/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0064\n",
      "Epoch 28/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0060\n",
      "Epoch 29/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 30/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 31/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0063\n",
      "Epoch 32/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 33/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0054\n",
      "Epoch 34/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 35/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 36/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 37/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 38/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0068\n",
      "Epoch 39/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 40/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 41/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0049\n",
      "Epoch 42/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0048\n",
      "Epoch 43/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0049\n",
      "Epoch 44/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 45/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 46/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 47/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0047\n",
      "Epoch 48/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 49/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0050\n",
      "Epoch 50/50\n",
      "\u001b[1m1769/1769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0047\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0076\n",
      "Epoch 2/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0065\n",
      "Epoch 3/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0066\n",
      "Epoch 4/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 5/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0086\n",
      "Epoch 6/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0078\n",
      "Epoch 7/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0068\n",
      "Epoch 8/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 9/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0074\n",
      "Epoch 10/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0072\n",
      "Epoch 11/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0061\n",
      "Epoch 12/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 13/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 14/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 15/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 16/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 17/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 18/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 19/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0065\n",
      "Epoch 20/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0063\n",
      "Epoch 22/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 23/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0060\n",
      "Epoch 24/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0069\n",
      "Epoch 25/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 26/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0054\n",
      "Epoch 27/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 28/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 29/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0053\n",
      "Epoch 30/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 31/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0064\n",
      "Epoch 32/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 33/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 34/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0049\n",
      "Epoch 35/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0062\n",
      "Epoch 36/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0049\n",
      "Epoch 37/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0067\n",
      "Epoch 38/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0047\n",
      "Epoch 39/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0056\n",
      "Epoch 40/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0051\n",
      "Epoch 41/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0049\n",
      "Epoch 42/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 43/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0055\n",
      "Epoch 44/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 45/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0044\n",
      "Epoch 46/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0058\n",
      "Epoch 47/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0057\n",
      "Epoch 48/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0059\n",
      "Epoch 49/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0052\n",
      "Epoch 50/50\n",
      "\u001b[1m1770/1770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "   Months Trained  Months Predicted  NO2 RMSE\n",
      "0              59                 1  0.000333\n",
      "1              58                 2  0.000326\n",
      "2              57                 3  0.000347\n",
      "3              56                 4  0.000322\n",
      "4              55                 5  0.000325\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Training on different subsets and predicting\n",
    "for months in range(1, 6):\n",
    "    time_step = 59 - months + 1  # Adjust time step\n",
    "    \n",
    "    # Prepare the data\n",
    "    X_no2, y_no2 = create_dataset(no2_data_scaled, time_step)\n",
    "    X_no2 = X_no2.reshape(X_no2.shape[0], X_no2.shape[1], 1)\n",
    "    \n",
    "    \n",
    "    # Build and train models\n",
    "    model_no2 = build_model()\n",
    "    model_no2.fit(X_no2, y_no2, epochs=50, batch_size=1, verbose=1)\n",
    "    \n",
    "    # Predictions\n",
    "    no2_pred = model_no2.predict(X_no2)\n",
    "    no2_pred = scaler.inverse_transform(no2_pred)\n",
    "    y_no2 = scaler.inverse_transform(y_no2.reshape(-1, 1))\n",
    "    \n",
    "    # RMSE\n",
    "    rmse_no2 = np.sqrt(mean_squared_error(y_no2, no2_pred))\n",
    "\n",
    "    # Store results\n",
    "    results.append({'Months Trained': 60 - months, 'Months Predicted': months, 'NO2 RMSE': rmse_no2})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72982dd5-d41c-4fd2-9e92-6d5b294bad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00020891239269139888\n",
      "0.2492509366332728\n",
      "0.24975055056131001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score\n",
    "# Mean Absolute error\n",
    "mae = mean_absolute_error(y_no2, no2_pred)\n",
    "r2=r2_score(y_no2, no2_pred)\n",
    "varience_score=explained_variance_score(y_no2, no2_pred)\n",
    "print(mae)\n",
    "print(r2)\n",
    "print(varience_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f89f81d5-e447-428f-94f9-a5f13907f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - loss: 0.0074\n",
      "Epoch 2/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - loss: 0.0068\n",
      "Epoch 3/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0062\n",
      "Epoch 4/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 0.0061\n",
      "Epoch 5/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0072\n",
      "Epoch 6/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0069\n",
      "Epoch 7/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 18ms/step - loss: 0.0059\n",
      "Epoch 8/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - loss: 0.0062\n",
      "Epoch 9/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0056\n",
      "Epoch 10/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0070\n",
      "Epoch 11/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0070\n",
      "Epoch 12/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0058\n",
      "Epoch 13/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - loss: 0.0063\n",
      "Epoch 14/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - loss: 0.0070\n",
      "Epoch 15/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0057\n",
      "Epoch 16/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0064\n",
      "Epoch 17/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0058\n",
      "Epoch 18/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0065\n",
      "Epoch 19/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0070\n",
      "Epoch 20/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0060\n",
      "Epoch 21/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0056\n",
      "Epoch 22/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0058\n",
      "Epoch 23/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0050\n",
      "Epoch 24/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 0.0055\n",
      "Epoch 25/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0063\n",
      "Epoch 26/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0056\n",
      "Epoch 27/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0058\n",
      "Epoch 28/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0049\n",
      "Epoch 29/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 0.0057\n",
      "Epoch 30/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0053\n",
      "Epoch 31/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 0.0058\n",
      "Epoch 32/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0058\n",
      "Epoch 33/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0058\n",
      "Epoch 34/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0051\n",
      "Epoch 35/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0057\n",
      "Epoch 36/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0052\n",
      "Epoch 37/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 0.0055\n",
      "Epoch 38/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - loss: 0.0049\n",
      "Epoch 39/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0056\n",
      "Epoch 40/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0062\n",
      "Epoch 41/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0044\n",
      "Epoch 42/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0046\n",
      "Epoch 43/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0058\n",
      "Epoch 44/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 0.0054\n",
      "Epoch 45/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0060\n",
      "Epoch 46/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0051\n",
      "Epoch 47/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0055\n",
      "Epoch 48/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0049\n",
      "Epoch 49/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0059\n",
      "Epoch 50/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - loss: 0.0050\n",
      "Epoch 1/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 22ms/step - loss: 0.0105\n",
      "Epoch 2/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 22ms/step - loss: 0.0095\n",
      "Epoch 3/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - loss: 0.0080\n",
      "Epoch 4/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 22ms/step - loss: 0.0084\n",
      "Epoch 5/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - loss: 0.0091\n",
      "Epoch 6/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - loss: 0.0093\n",
      "Epoch 7/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0091\n",
      "Epoch 8/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0081\n",
      "Epoch 9/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0078\n",
      "Epoch 10/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0084\n",
      "Epoch 11/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0086\n",
      "Epoch 12/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0088\n",
      "Epoch 13/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0080\n",
      "Epoch 14/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0086\n",
      "Epoch 15/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - loss: 0.0083\n",
      "Epoch 16/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0102\n",
      "Epoch 17/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 21ms/step - loss: 0.0082\n",
      "Epoch 18/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - loss: 0.0081\n",
      "Epoch 19/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - loss: 0.0091\n",
      "Epoch 20/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0088\n",
      "Epoch 21/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0082\n",
      "Epoch 22/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0085\n",
      "Epoch 23/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0092\n",
      "Epoch 24/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0089\n",
      "Epoch 25/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0087\n",
      "Epoch 26/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0085\n",
      "Epoch 27/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0082\n",
      "Epoch 28/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0085\n",
      "Epoch 29/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0093\n",
      "Epoch 30/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0082\n",
      "Epoch 31/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - loss: 0.0077\n",
      "Epoch 32/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0082\n",
      "Epoch 33/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0078\n",
      "Epoch 34/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0079\n",
      "Epoch 35/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0089\n",
      "Epoch 36/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0088\n",
      "Epoch 37/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0079\n",
      "Epoch 38/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0097\n",
      "Epoch 39/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0080\n",
      "Epoch 40/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0084\n",
      "Epoch 41/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0084\n",
      "Epoch 42/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0077\n",
      "Epoch 43/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0077\n",
      "Epoch 44/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0080\n",
      "Epoch 45/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0082\n",
      "Epoch 46/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0077\n",
      "Epoch 47/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0078\n",
      "Epoch 48/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - loss: 0.0082\n",
      "Epoch 49/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0082\n",
      "Epoch 50/50\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - loss: 0.0078\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step\n",
      "   Train Months  Predict Months  NO2 RMSE  NO2 MAE    NO2 R²  SO2 RMSE  \\\n",
      "0            50              10  0.000078  0.00005  0.223199  0.000411   \n",
      "\n",
      "    SO2 MAE    SO2 R²  \n",
      "0  0.000261  0.054836  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, explained_variance_score, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Select columns related to NO2 and SO2\n",
    "no2_data = data['NO2'].values.reshape(-1, 1)\n",
    "so2_data = data['SO2'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize the data\n",
    "scaler_no2 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_so2 = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "no2_data_scaled = scaler_no2.fit_transform(no2_data)\n",
    "so2_data_scaled = scaler_so2.fit_transform(so2_data)\n",
    "\n",
    "# Function to create dataset\n",
    "def create_dataset(dataset, time_step):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Build LSTM model\n",
    "def build_model(time_step):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Set training and prediction periods\n",
    "train_months = 50\n",
    "predict_months = 10\n",
    "time_step = train_months\n",
    "\n",
    "# Prepare the data\n",
    "X_no2, y_no2 = create_dataset(no2_data_scaled, time_step)\n",
    "X_no2 = X_no2.reshape(X_no2.shape[0], X_no2.shape[1], 1)\n",
    "\n",
    "X_so2, y_so2 = create_dataset(so2_data_scaled, time_step)\n",
    "X_so2 = X_so2.reshape(X_so2.shape[0], X_so2.shape[1], 1)\n",
    "\n",
    "# Build and train models\n",
    "model_no2 = build_model(time_step)\n",
    "model_no2.fit(X_no2, y_no2, epochs=50, batch_size=1, verbose=1)\n",
    "\n",
    "model_so2 = build_model(time_step)\n",
    "model_so2.fit(X_so2, y_so2, epochs=50, batch_size=1, verbose=1)\n",
    "\n",
    "# Predictions\n",
    "no2_pred = model_no2.predict(X_no2)\n",
    "no2_pred = scaler_no2.inverse_transform(no2_pred)\n",
    "y_no2 = scaler_no2.inverse_transform(y_no2.reshape(-1, 1))\n",
    "\n",
    "so2_pred = model_so2.predict(X_so2)\n",
    "so2_pred = scaler_so2.inverse_transform(so2_pred)\n",
    "y_so2 = scaler_so2.inverse_transform(y_so2.reshape(-1, 1))\n",
    "\n",
    "# Calculate metrics for NO2\n",
    "rmse_no2 = np.sqrt(mean_squared_error(y_no2, no2_pred))\n",
    "mae_no2 = mean_absolute_error(y_no2, no2_pred)\n",
    "r2_no2 = r2_score(y_no2, no2_pred)\n",
    "\n",
    "# Calculate metrics for SO2\n",
    "rmse_so2 = np.sqrt(mean_squared_error(y_so2, so2_pred))\n",
    "mae_so2 = mean_absolute_error(y_so2, so2_pred)\n",
    "r2_so2 = r2_score(y_so2, so2_pred)\n",
    "\n",
    "# Print results\n",
    "results = {\n",
    "    'Train Months': train_months,\n",
    "    'Predict Months': predict_months,\n",
    "    'NO2 RMSE': rmse_no2,\n",
    "    'NO2 MAE': mae_no2,\n",
    "    'NO2 R²': r2_no2,\n",
    "    'SO2 RMSE': rmse_so2,\n",
    "    'SO2 MAE': mae_so2,\n",
    "    'SO2 R²': r2_so2\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee40b4-c39f-4a6f-bedb-dc6b1230de6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
